{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import gensim\n",
    "from tqdm import tqdm\n",
    "from gensim.models import Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "import nltk\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import utils\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data1 =pd.read_csv('Datasets/label_train.csv')\n",
    "unlabel1 = pd.read_csv('Datasets/unlabel1_final.csv')\n",
    "unlabel2 = pd.read_csv('Datasets/unlabel2_final.csv')\n",
    "unlabel3 = pd.read_csv('Datasets/unlabel3_final.csv')\n",
    "unlabel4 = pd.read_csv('Datasets/unlabel4_final.csv')\n",
    "unlabel5 = pd.read_csv('Datasets/unlabel5_final.csv')\n",
    "unlabel6 = pd.read_csv('Datasets/unlabel6_final.csv')\n",
    "test_file = pd.read_csv('Datasets/test_file.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # train_data = train_data.dropna()\n",
    "# unlabel1 = unlabel1.dropna()\n",
    "train_data1 = train_data1.drop(columns ='Unnamed: 0',axis = 1)\n",
    "test_file = test_file.drop(columns ='Unnamed: 0',axis = 1)\n",
    "unlabel1 = unlabel1.drop(columns ='Unnamed: 0',axis = 1)\n",
    "unlabel2 = unlabel2.drop(columns ='Unnamed: 0',axis = 1)\n",
    "unlabel3 = unlabel3.drop(columns ='Unnamed: 0',axis = 1)\n",
    "unlabel4 = unlabel4.drop(columns ='Unnamed: 0',axis = 1)\n",
    "unlabel5 = unlabel5.drop(columns ='Unnamed: 0',axis = 1)\n",
    "unlabel6 = unlabel6.drop(columns ='Unnamed: 0',axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the training data into test and train\n",
    "train_data, test1 = train_test_split(train_data1, test_size = 0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting test and train and predictors and labels\n",
    "\n",
    "X_train = train_data['text']\n",
    "Y_train = train_data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test1['text']\n",
    "Y_test = test1['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_test = unlabel1['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 65406\n",
      "x_train: <40000x65406 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5679409 stored elements in Compressed Sparse Row format>\n",
      "x_test: <100000x65406 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 14084484 stored elements in Compressed Sparse Row format>\n",
      "Number of features: 65406\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tf_vectoriser = TfidfVectorizer(sublinear_tf = True,\n",
    "                               analyzer = 'word',\n",
    "                               max_df = 0.95,\n",
    "                               min_df = 10,\n",
    "                               ngram_range = (1,2),use_idf = True)\n",
    "\n",
    "x_train = tf_vectoriser.fit_transform(X_train)\n",
    "x_test = tf_vectoriser.transform(X_test)\n",
    "x1_test = tf_vectoriser.transform(X1_test)\n",
    "\n",
    "print(\"Vocab size: {}\".format(len(tf_vectoriser.vocabulary_)))\n",
    "print(\"x_train: {}\".format(repr(x_train)))\n",
    "print(\"x_test: {}\".format(repr(x1_test)))\n",
    "\n",
    "feature_names = tf_vectoriser.get_feature_names()\n",
    "print(\"Number of features: {}\".format(len(feature_names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sad: (40000,)\n",
      "Smile: (40000,)\n",
      "Laugh (40000,)\n",
      "Very happy: (40000,)\n",
      "crying: (40000,)\n",
      "tongueOut: (40000,)\n",
      "wink: (40000,)\n",
      "kiss: (40000,)\n",
      "surprise: (40000,)\n",
      "disgust: (40000,)\n",
      "exclamation: (40000,)\n",
      "capital_Ratio: (40000,)\n"
     ]
    }
   ],
   "source": [
    "# Adding emoticons for training\n",
    "\n",
    "sad = np.array(train_data['sad'])\n",
    "print(\"Sad:\",sad.shape)\n",
    "smile = np.array(train_data['smile'])\n",
    "print(\"Smile:\",smile.shape)\n",
    "laugh = np.array(train_data['laugh'])\n",
    "print(\"Laugh\",laugh.shape)\n",
    "very_happy = np.array(train_data['very_happy'])\n",
    "print(\"Very happy:\",very_happy.shape)\n",
    "crying = np.array(train_data['crying'])\n",
    "print(\"crying:\",crying.shape)\n",
    "tongueOut = np.array(train_data['tongueOut'])\n",
    "print(\"tongueOut:\",tongueOut.shape)\n",
    "wink = np.array(train_data['wink'])\n",
    "print(\"wink:\",wink.shape)\n",
    "kiss = np.array(train_data['kiss'])\n",
    "print(\"kiss:\",kiss.shape)\n",
    "surprise = np.array(train_data['surprise'])\n",
    "print(\"surprise:\",surprise.shape)\n",
    "disgust = np.array(train_data['disgust'])\n",
    "print(\"disgust:\",disgust.shape)\n",
    "exclamation = np.array(train_data['exclamation'])\n",
    "print(\"exclamation:\",exclamation.shape)\n",
    "capital_Ratio = np.array(train_data['capital_Ratio'])\n",
    "print(\"capital_Ratio:\",capital_Ratio.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sad: (10000,)\n",
      "Smile: (10000,)\n",
      "Laugh (10000,)\n",
      "Very happy: (10000,)\n",
      "crying: (10000,)\n",
      "tongueOut: (10000,)\n",
      "wink: (10000,)\n",
      "kiss: (10000,)\n",
      "surprise: (10000,)\n",
      "disgust: (10000,)\n",
      "exclamation: (10000,)\n",
      "capital_Ratio: (10000,)\n"
     ]
    }
   ],
   "source": [
    "# Adding emoticons for TEST\n",
    "\n",
    "sad1 = np.array(test1['sad'])\n",
    "print(\"Sad:\",sad1.shape)\n",
    "smile1 = np.array(test1['smile'])\n",
    "print(\"Smile:\",smile1.shape)\n",
    "laugh1 = np.array(test1['laugh'])\n",
    "print(\"Laugh\",laugh1.shape)\n",
    "very_happy1 = np.array(test1['very_happy'])\n",
    "print(\"Very happy:\",very_happy1.shape)\n",
    "crying1 = np.array(test1['crying'])\n",
    "print(\"crying:\",crying1.shape)\n",
    "tongueOut1 = np.array(test1['tongueOut'])\n",
    "print(\"tongueOut:\",tongueOut1.shape)\n",
    "wink1 = np.array(test1['wink'])\n",
    "print(\"wink:\",wink1.shape)\n",
    "kiss1 = np.array(test1['kiss'])\n",
    "print(\"kiss:\",kiss1.shape)\n",
    "surprise1 = np.array(test1['surprise'])\n",
    "print(\"surprise:\",surprise1.shape)\n",
    "disgust1 = np.array(test1['disgust'])\n",
    "print(\"disgust:\",disgust1.shape)\n",
    "exclamation1 = np.array(test1['exclamation'])\n",
    "print(\"exclamation:\",exclamation1.shape)\n",
    "capital_Ratio1 = np.array(test1['capital_Ratio'])\n",
    "print(\"capital_Ratio:\",capital_Ratio1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sad: (100000,)\n",
      "Smile: (100000,)\n",
      "Laugh (100000,)\n",
      "Very happy: (100000,)\n",
      "crying: (100000,)\n",
      "tongueOut: (100000,)\n",
      "wink: (100000,)\n",
      "kiss: (100000,)\n",
      "surprise: (100000,)\n",
      "disgust: (100000,)\n",
      "exclamation: (100000,)\n",
      "capital_Ratio: (100000,)\n"
     ]
    }
   ],
   "source": [
    "# Adding emoticons for X1_test (unlabled data)\n",
    "\n",
    "sad2 = np.array(unlabel1['sad'])\n",
    "print(\"Sad:\",sad2.shape)\n",
    "smile2 = np.array(unlabel1['smile'])\n",
    "print(\"Smile:\",smile2.shape)\n",
    "laugh2 = np.array(unlabel1['laugh'])\n",
    "print(\"Laugh\",laugh2.shape)\n",
    "very_happy2 = np.array(unlabel1['very_happy'])\n",
    "print(\"Very happy:\",very_happy2.shape)\n",
    "crying2 = np.array(unlabel1['crying'])\n",
    "print(\"crying:\",crying2.shape)\n",
    "tongueOut2 = np.array(unlabel1['tongueOut'])\n",
    "print(\"tongueOut:\",tongueOut2.shape)\n",
    "wink2 = np.array(unlabel1['wink'])\n",
    "print(\"wink:\",wink2.shape)\n",
    "kiss2 = np.array(unlabel1['kiss'])\n",
    "print(\"kiss:\",kiss2.shape)\n",
    "surprise2 = np.array(unlabel1['surprise'])\n",
    "print(\"surprise:\",surprise2.shape)\n",
    "disgust2 = np.array(unlabel1['disgust'])\n",
    "print(\"disgust:\",disgust2.shape)\n",
    "exclamation2 = np.array(unlabel1['exclamation'])\n",
    "print(\"exclamation:\",exclamation2.shape)\n",
    "capital_Ratio2 = np.array(unlabel1['capital_Ratio'])\n",
    "print(\"capital_Ratio:\",capital_Ratio2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding features to sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack\n",
    "\n",
    "# Adding features for training file\n",
    "\n",
    "X_train_dtm = hstack((x_train,sad[:,None]))\n",
    "X_train_dtm = hstack((X_train_dtm,smile[:,None]))\n",
    "X_train_dtm = hstack((X_train_dtm,laugh[:,None]))\n",
    "X_train_dtm = hstack((X_train_dtm,very_happy[:,None]))\n",
    "X_train_dtm = hstack((X_train_dtm,crying[:,None]))\n",
    "X_train_dtm = hstack((X_train_dtm,tongueOut[:,None]))\n",
    "X_train_dtm = hstack((X_train_dtm,wink[:,None]))\n",
    "X_train_dtm = hstack((X_train_dtm,kiss[:,None]))\n",
    "X_train_dtm = hstack((X_train_dtm,surprise[:,None]))\n",
    "X_train_dtm = hstack((X_train_dtm,disgust[:,None]))\n",
    "X_train_dtm = hstack((X_train_dtm,exclamation[:,None]))\n",
    "X_train_dtm = hstack((X_train_dtm,capital_Ratio[:,None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding features for testing file\n",
    "\n",
    "X_test_dtm = hstack((x_test,sad1[:,None]))\n",
    "X_test_dtm = hstack((X_test_dtm,smile1[:,None]))\n",
    "X_test_dtm = hstack((X_test_dtm,laugh1[:,None]))\n",
    "X_test_dtm = hstack((X_test_dtm,very_happy1[:,None]))\n",
    "X_test_dtm = hstack((X_test_dtm,crying1[:,None]))\n",
    "X_test_dtm = hstack((X_test_dtm,tongueOut1[:,None]))\n",
    "X_test_dtm = hstack((X_test_dtm,wink1[:,None]))\n",
    "X_test_dtm = hstack((X_test_dtm,kiss1[:,None]))\n",
    "X_test_dtm = hstack((X_test_dtm,surprise1[:,None]))\n",
    "X_test_dtm = hstack((X_test_dtm,disgust1[:,None]))\n",
    "X_test_dtm = hstack((X_test_dtm,exclamation1[:,None]))\n",
    "X_test_dtm = hstack((X_test_dtm,capital_Ratio1[:,None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding features for X1_test file (unlabled data)\n",
    "\n",
    "X1_test_dtm = hstack((x1_test,sad2[:,None]))\n",
    "X1_test_dtm = hstack((X1_test_dtm,smile2[:,None]))\n",
    "X1_test_dtm = hstack((X1_test_dtm,laugh2[:,None]))\n",
    "X1_test_dtm = hstack((X1_test_dtm,very_happy2[:,None]))\n",
    "X1_test_dtm = hstack((X1_test_dtm,crying2[:,None]))\n",
    "X1_test_dtm = hstack((X1_test_dtm,tongueOut2[:,None]))\n",
    "X1_test_dtm = hstack((X1_test_dtm,wink2[:,None]))\n",
    "X1_test_dtm = hstack((X1_test_dtm,kiss2[:,None]))\n",
    "X1_test_dtm = hstack((X1_test_dtm,surprise2[:,None]))\n",
    "X1_test_dtm = hstack((X1_test_dtm,disgust2[:,None]))\n",
    "X1_test_dtm = hstack((X1_test_dtm,exclamation2[:,None]))\n",
    "X1_test_dtm = hstack((X1_test_dtm,capital_Ratio2[:,None]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(X_train_dtm, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.6181\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"Accuracy : \", accuracy_score(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rachana.LAPTOP-2JO12NAC\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train_dtm,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf = rf.predict(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.4249\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"Accuracy : \", accuracy_score(Y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bynode=1, colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=3, min_child_weight=1, missing=None,\n",
       "       n_estimators=100, n_jobs=1, nthread=None,\n",
       "       objective='multi:softprob', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=None,\n",
       "       subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost\n",
    "from xgboost import XGBClassifier\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(X_train_dtm,Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rachana.LAPTOP-2JO12NAC\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "predxgb = xgb.predict(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.5267\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"Accuracy : \", accuracy_score(Y_test, predxgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-layer perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier()\n",
    "mlp.fit(X_train_dtm,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_mlp = mlp.predict(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.5336\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"Accuracy : \", accuracy_score(Y_test, pred_mlp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Booster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=5,\n",
       "              max_features=0.5, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              presort='auto', random_state=999999, subsample=1.0,\n",
       "              verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gbi = GradientBoostingClassifier(learning_rate=0.1,max_depth=5,max_features=0.5,random_state=999999)\n",
    "gbi.fit(X_train_dtm,Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "predgbi = gbi.predict(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.5543\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"Accuracy : \", accuracy_score(Y_test, predgbi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(X_train_dtm, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.6025\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"Accuracy : \", accuracy_score(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
